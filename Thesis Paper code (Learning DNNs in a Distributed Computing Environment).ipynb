{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "scheduler_address = \"tcp://10.108.56.79:8786\"\n",
    "client = Client(scheduler_address)\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset(\"Bingsu/Cat_and_Dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load the model - ResNet18 in this example\n",
    "model = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n",
    "model = model.to('cpu')  # Ensure model is on CPU for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "model_future = client.scatter(model, broadcast=True) # send the model to each worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, data_loader, epochs, lr):\n",
    "    device = 'cpu'\n",
    "\n",
    "    model.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        with tqdm(data_loader, desc=f'Epoch {epoch + 1}/{epochs}', unit='batch') as pbar:\n",
    "            total_loss = 0.0\n",
    "            for images, labels in pbar:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = F.cross_entropy(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "            print(f'Epoch {epoch+1}, Average Loss: {total_loss / len(data_loader)}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, wait\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader, Subset, Dataset as TorchDataset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "# Define a custom dataset class\n",
    "class CustomImageDataset(TorchDataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.df.iloc[idx]['file']\n",
    "        label = self.df.iloc[idx]['label']\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    \n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Convert dataset to CustomImageDataset\n",
    "train_df = pd.DataFrame(dataset['train'])\n",
    "test_df = pd.DataFrame(dataset['test'])\n",
    "train_dataset = CustomImageDataset(train_df, transform=transform)\n",
    "test_dataset = CustomImageDataset(test_df, transform=transform)\n",
    "\n",
    "# Create DataLoader with batch size 32\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with batch dispatching and model aggregation\n",
    "epochs = 7\n",
    "learning_rate = 0.001\n",
    "num_workers = 4\n",
    "for epoch in range(epochs):\n",
    "    batch_iter = iter(train_loader)\n",
    "\n",
    "    while True:\n",
    "        # Prepare batches for each worker\n",
    "        batch_groups = [list(chain.from_iterable([next(batch_iter, None) for _ in range(1)])) for _ in range(num_workers)]\n",
    "        if None in batch_groups:\n",
    "            break  # End of DataLoader\n",
    "\n",
    "        # Submit training tasks\n",
    "        futures = [client.submit(train, model_future, batch_group, 1, learning_rate) for batch_group in batch_groups]\n",
    "\n",
    "        # Wait for all tasks to complete\n",
    "        results = client.gather(futures)\n",
    "\n",
    "        # Synchronize models by summing weights\n",
    "        state_dicts, losses = zip(*results)\n",
    "        updated_state_dict = {key: sum(d[key] for d in state_dicts)}\n",
    "\n",
    "        # Update the model with the averaged state dict\n",
    "        model.load_state_dict(updated_state_dict)\n",
    "\n",
    "        # Scatter the updated model back to the workers\n",
    "        model_future = client.scatter(model, broadcast=True)\n",
    "\n",
    "trained_model = client.gather(model_future)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "test_accuracy = test_model(trained_model, test_loader)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
