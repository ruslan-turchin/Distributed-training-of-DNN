{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " scheduler_address = \"tcp://10.105.157.106:80\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(scheduler_address)\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset(\"Bingsu/Cat_and_Dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "model_resnet18 = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def train(model, optimizer, loss_fn, train_loader, test_loader, epochs=5):\n",
    "\n",
    "    # model = model.to(device)\n",
    "    # model = model.share_memory()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "\n",
    "        # Create a progress bar for the training loop\n",
    "        with tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Epoch {epoch + 1}/{epochs}', dynamic_ncols=True, unit='batch', unit_scale=True) as train_progress_bar:\n",
    "            start_time = time.time()\n",
    "            for batch_idx, batch in train_progress_bar:\n",
    "\n",
    "                # batch = [b for b in batch]\n",
    "                # futures = client.map(lambda data: model(data[0]), batch)\n",
    "\n",
    "                # losses = client.map(loss_fn, futures, batch[1])\n",
    "                # loss = client.submit(torch.mean, client.gather(losses))\n",
    "                # # Compute the gradients and update the model parameters\n",
    "                # optimizer.zero_grad()\n",
    "                # gradients = client.map(lambda loss, future: torch.autograd.grad(loss, future)[0], loss, futures)\n",
    "                # gradients =client.submit(torch.mean, client.gather(gradients))\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                inputs, targets = batch['image'], batch['labels']\n",
    "                output = model(inputs)\n",
    "                loss = loss_fn(output, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                training_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Update the progress bar\n",
    "                train_progress_bar.set_postfix({'Training Loss': training_loss})\n",
    "\n",
    "        training_loss /= len(train_loader.dataset)\n",
    "\n",
    "        print('Epoch: {}, Training Loss: {:.4f}'.format(epoch, training_loss))\n",
    "\n",
    "\n",
    "    # client.map(lambda parameter, gradient: parameter.grad.copy_(gradient), model.parameters(), gradients)\n",
    "    #optimizer.step()\n",
    "\n",
    "            # model.eval()\n",
    "        # num_correct = 0\n",
    "        # num_examples = 0\n",
    "\n",
    "\n",
    "        # # Create a progress bar for the testing loop\n",
    "        # with tqdm(enumerate(test_loader), total=len(test_loader), desc='Testing', dynamic_ncols=True, unit='batch', unit_scale=True) as test_progress_bar:\n",
    "        #     for batch_idx, batch in test_progress_bar:\n",
    "        #         inputs, targets = batch['image'], batch['labels']\n",
    "        #         output = model(inputs)\n",
    "        #         loss = loss_fn(output, targets)\n",
    "        #         valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        #         correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
    "        #         num_correct += torch.sum(correct).item()\n",
    "        #         num_examples += correct.shape[0]\n",
    "\n",
    "        # valid_loss /= len(test_loader.dataset)\n",
    "\n",
    "        # # Display the training and testing results with accuracy\n",
    "        # print('Epoch: {}, Training Loss: {:.4f}, Testing Loss: {:.4f}, accuracy_test = {:.4f}'.format(epoch, training_loss,\n",
    "        #                                                                                               valid_loss, num_correct / num_examples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "img_dimensions = 224\n",
    "\n",
    "\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_dimensions, img_dimensions)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n",
    "    ])\n",
    "\n",
    "img_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_dimensions,img_dimensions)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n",
    "    ])\n",
    "\n",
    "def transforms_h (data):\n",
    "  data['image'] = [img_transforms(i) for i in data['image']]\n",
    "  return data\n",
    "\n",
    "def check_image(path):\n",
    "    try:\n",
    "        im = Image.open(path)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "num_workers = 6\n",
    "\n",
    "\n",
    "dataset.set_transform(transforms_h)\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(dataset['train'], batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_data_loader = torch.utils.data.DataLoader(dataset['test'], batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Num training images: {len(train_data_loader.dataset)}')\n",
    "print(f'Num test images: {len(test_data_loader.dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_data_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_data_loader:\n",
    "            images, labels = data['image'].to(device), data['labels'].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('correct: {:d}  total: {:d}'.format(correct, total))\n",
    "    print('accuracy = {:f}'.format(correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model_resnet18.parameters(), lr=0.0001)\n",
    "train(model_resnet18, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, test_data_loader, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model_resnet18, test_data_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-python3-kernel",
   "language": "python",
   "name": "my-python3-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
